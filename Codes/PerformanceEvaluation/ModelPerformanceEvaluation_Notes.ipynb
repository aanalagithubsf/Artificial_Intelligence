{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"FeatureEng_PerfEval.svg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.591%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using a train and a test set\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "filename = 'pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names, skiprows=1)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7 # to ensure that the results are reproducible\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7012987  0.81818182 0.74025974 0.71428571 0.77922078 0.75324675\n",
      " 0.85714286 0.80519481 0.72368421 0.80263158]\n",
      "Accuracy: 76.951% (4.841%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Cross Validation\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "filename = 'pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names, skiprows=1)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "Accuracy: 76.823% (42.196%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Leave One Out Cross Validation\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "filename = 'pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names, skiprows=1)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "results = cross_val_score(model, X, Y, cv=loocv)\n",
    "print(results)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "standard deviation score has more variance than the k-fold cross-validation results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle Split Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.575% (1.654%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Shuffle Split Cross Validation\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "filename = 'pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names, skiprows=1)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "# kfold = KFold(n_splits=10, random_state=7)\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# results = cross_val_score(model, X, Y, cv=kfold)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the speed of using a train/test split and the reduction in variance in the estimated performance of k-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold\n",
      "TRAIN: [0 1 2 4 5 6 7 9] TEST: [3 8]\n",
      "TRAIN: [1 2 3 4 5 7 8 9] TEST: [0 6]\n",
      "TRAIN: [0 1 3 4 5 6 8 9] TEST: [2 7]\n",
      "TRAIN: [0 1 2 3 6 7 8 9] TEST: [4 5]\n",
      "TRAIN: [0 2 3 4 5 6 7 8] TEST: [1 9]\n",
      "Shuffle Split\n",
      "TRAIN: [8 4 1 0 6 5 7 2] TEST: [3 9]\n",
      "TRAIN: [7 0 3 9 4 5 1 6] TEST: [8 2]\n",
      "TRAIN: [1 2 5 6 4 8 9 0] TEST: [3 7]\n",
      "TRAIN: [4 6 7 8 3 5 1 2] TEST: [9 0]\n",
      "TRAIN: [7 2 6 5 4 3 0 9] TEST: [1 8]\n"
     ]
    }
   ],
   "source": [
    "splits = 5\n",
    "\n",
    "tx = range(10)\n",
    "ty = [0] * 5 + [1] * 5\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\n",
    "shufflesplit = StratifiedShuffleSplit(n_splits=splits, random_state=42, test_size=2)\n",
    "\n",
    "print(\"KFold\")\n",
    "for train_index, test_index in kfold.split(tx, ty):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "print(\"Shuffle Split\")\n",
    "for train_index, test_index in shufflesplit.split(tx, ty):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 1 2 3 4 5 6 7 8 9\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K - Fold Cross Validation\n",
    "shuffle-  3 4 5 2 1 8 7 9 0 6\n",
    "k = 5\n",
    "3 4 - 5 2 - 1 8 - 7 9 - 0 6\n",
    "3 4 \n",
    "5 2\n",
    "1 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shuffle split\n",
    "3 4 5 2 1 8 7 9 0 6\n",
    "k = 5\n",
    "3 4 - 5 2 - 1 8 - 7 9 - 0 6\n",
    "3 4 - Test\n",
    "\n",
    "3 6 9 1 2 0 5 4 8 7\n",
    "k = 5\n",
    "3 6 - 9 1 - 2 0 - 5 4 - 8 7\n",
    "3 6 - Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 1 2 3 4 5 6 7 8 9\n",
    "0 1 2 3 4 5 6 - Train\n",
    "7 8 9- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 1 0 4 4 5 6 - train\n",
    "0 2 3 4 5 5 6 - train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: array([-1.08011358e-01,  4.64204584e-02,  2.05586264e-02,  2.68673382e+00,\n",
      "       -1.77666112e+01,  3.80986521e+00,  6.92224640e-04, -1.47556685e+00,\n",
      "        3.06049479e-01, -1.23345939e-02, -9.52747232e-01,  9.31168327e-03,\n",
      "       -5.24758378e-01])\n",
      "\n",
      "Intercept: 36.459488385090125\n",
      "\n",
      "Linear: 0.7406426641094095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LinearRegression\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, Y)\n",
    "print('Coefficients: {}\\n'.format(repr(reg.coef_)))\n",
    "print('Intercept: {}\\n'.format(reg.intercept_))\n",
    "r = reg.score(X, Y)\n",
    "print('Linear: {}\\n'.format(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: array([-1.07473720e-01,  4.65716366e-02,  1.59989982e-02,  2.67001859e+00,\n",
      "       -1.66846452e+01,  3.81823322e+00, -2.69060598e-04, -1.45962557e+00,\n",
      "        3.03515266e-01, -1.24205910e-02, -9.40758541e-01,  9.36807461e-03,\n",
      "       -5.25966203e-01])\n",
      "\n",
      "Intercept: 35.69365371165904\n",
      "\n",
      "R2: 0.7406002922228037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "reg = Ridge(alpha=0.1)\n",
    "reg.fit(X, Y)\n",
    "print('Coefficients: {}\\n'.format(repr(reg.coef_)))\n",
    "print('Intercept: {}\\n'.format(reg.intercept_))\n",
    "r2 = reg.score(X, Y)\n",
    "print('R2: {}\\n'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: array([-0.09789363,  0.04921111, -0.03661906,  0.95519003, -0.        ,\n",
      "        3.70320175, -0.01003698, -1.16053834,  0.27470721, -0.01457017,\n",
      "       -0.77065434,  0.01024917, -0.56876914])\n",
      "\n",
      "Intercept: 25.577073179662115\n",
      "\n",
      "R1: 0.7269834862602695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "reg = Lasso(alpha=0.1)\n",
    "reg.fit(X, Y)\n",
    "print('Coefficients: {}\\n'.format(repr(reg.coef_)))\n",
    "print('Intercept: {}\\n'.format(reg.intercept_))\n",
    "r1 = reg.score(X, Y)\n",
    "print('R1: {}\\n'.format(r1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: array([-0.1000792 ,  0.05137652, -0.0459005 ,  0.98797012, -0.05953271,\n",
      "        3.25266223, -0.007219  , -1.18140247,  0.28872571, -0.0149519 ,\n",
      "       -0.79350234,  0.00996304, -0.59818437])\n",
      "\n",
      "Intercept: 29.329790278160026\n",
      "\n",
      "ElasticNet: 0.7256797684938825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "reg = ElasticNet(alpha=0.1)\n",
    "reg.fit(X, Y)\n",
    "print('Coefficients: {}\\n'.format(repr(reg.coef_)))\n",
    "print('Intercept: {}\\n'.format(reg.intercept_))\n",
    "r1 = reg.score(X, Y)\n",
    "print('ElasticNet: {}\\n'.format(r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,x3,x4,x5 -> y , 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1*x1 + w2*x2 + w3*x3 + w4*x4 + w5*x5 + b = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((w1*x1 + w2*x2 + w3*x3 + w4*x4 + w5*x5)  - y)2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = w1 - [L + alpha * L2(w1)] \n",
    "w2 = w2 - [L + alpha * L2(w2)]\n",
    "w3 = w3 - [L + alpha * L2(w3)]\n",
    "w4 = w4 - [L + alpha * L2(w4)]\n",
    "w5 = w5 - [L + alpha * L2(w5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.2*x1 + 0.7*x2 + 50*x3 + 5*x4 + 1200*x5 + b = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5 x1 + 0.2 x2 + 2 * x3 + 1.1 x4 + 30 * x5 + b = y  # L2 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 * x1 + 0 * x2 + 2 * x3 + 1.1 x4 + 30 * x5 + b = y  # L1 Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
